## Overview

Every day over 450 million photos and videos are being uploaded to Facebook and Instagram. The exponential growth of visual media has made quality assessment become increasingly important for various applications, including image and video acquisition, synthesis, restoration, enhancement, search and retrieval, storage, and recognition. 

Broadly, visual quality assessment techniques can be divided into image and video technical quality assessment (IQA and VQA, or broadly TQA) and aesthetics quality assessment (AQA). TQA focuses on the effect of image-level technical aspects of perceived quality, such as sharpness, noise, color reproduction, contrast, dynamic range, and others. On the other hand, AQA deals with more abstract aesthetics-related quality factors that capture the subjective aesthetics experience. Aesthetics judgments are associated with the adherence to established photographic rules encompassing lighting (emphasis, contrast), composition, colors, and more. Even though these topics have mostly been studied independently, they represent tightly related aspects of the same underlying subjective experience of media items, value judgments. 

This workshop aims to bring together individuals in the two fields of TQA and AQA for sharing of ideas and discussions on current trends, developments, issues, and future directions, with the vision to accelerate the progress of research in both fields. Our hope is that bridging TQA and AQA, will result in a better understanding of quantitative measures of quality of experience in the broader context of multimedia applications.

### Scope 

The scope of this workshop spans:
* **Analysis and prediction of aesthetic and technical visual quality**, encompassing absolute and comparative judgments about visual media:
  * Traditional and deep-learning-based approaches
  * Aesthetics and QoE related concepts such as interestingness, popularity, viralness
* **Datasets for TQA and AQA**, including:
  * New approaches to data collection procedures and sources
  * New data augmentation methods	
* **Applications of TQA and AQA** in computer vision or image processing tasks:
  * Visual filtering and retrieval (recommendation, image gallery/video)
  * Visual editing (recomposition, retargeting, cropping)
  * Assessment guided visual enhancement
  * Real-world systems and applications
  * Applications to media such as light fields, 360 or stereo, point clouds.
 
<br/>

## Important dates

|||
| :--- |---: |
| Submission Deadline for Workshop Papers       |  ~~July 30th 2020~~ August 10th 2020  |
| Notification of Acceptance of Workshop Papers |  August 26th 2020   |
| Workshop Camera-Ready Papers Due by           |  September 2nd 2020 |
| Workshop date                                 |  October 12th 2020 |

All deadlines are at midnight (23:59) Anywhere on Earth.

> These are the latest updates since September 21st 2020. 

<br/>

## Paper submission

Authors are invited to submit a full paper (two-column format, 6-8 pages, not including references) electronically according to the guidelines available on the conference website at [2020.acmmm.org](https://2020.acmmm.org/). We use the same formatting template as ACM Multimedia 2019. All contributions must be submitted through CMT using the following link: [cmt3.research.microsoft.com/MMW2020](https://cmt3.research.microsoft.com/MMW2020).<br/>
Accepted papers will be published in the ACM Digital Library alongside the ACM Multimedia main conference papers.

Please find the <a href="assets/docs/ATQAM-CFP.pdf"><img src="assets/images/icons/paperclip.png" style="width:25px"/> call for papers here</a>.
<br/>

## Invited speakers

<img src="assets/images/alan-bovik.png" alt="Alan Conrad Bovik" class="speaker"/>

[Alan Conrad Bovik](http://www.ece.utexas.edu/people/faculty/alan-bovik) is an American engineer and vision scientist. He is a Professor at The University of Texas at Austin (UT-Austin), where he holds the Cockrell Family Regents Endowed Chair and is Director of the Laboratory for Image and Video Engineering. He is a faculty member in the UT-Austin Department of Electrical and Computer Engineering, the Institute for Neuroscience, and the Wireless Networking and Communications Group. Bovik won a Primetime Emmy Award in 2015 for his development of video quality measurement tools that are now standards in television production. Two of Bovik's research publications in the area of visual image quality have been recognized as 2017 Google Scholar Classic Papers, which are selected for being highly-cited papers that have stood the test of time, and are among the ten most-cited articles in their area of research published ten years earlier.

_Talk title: "Speeding it Up: Perception of High-Frame Rate Videos"_

<img src="assets/images/james-wang.png" alt="James Z. Wang" class="speaker"/>

[James Z. Wang](http://infolab.stanford.edu/~wangz/home/) is a professor at Pennsylvania State University. Wang's research seeks to advance knowledge through modeling objects, concepts, aesthetics, and emotions in big visual data. He is well-known for his pioneering research in the field of aesthetics quality assessment. His research team have developed the ACQUINE aesthetic quality inference engine, SIMPLIcity semantics-sensitive image retrieval system, the ALIPR real-time computerized image tagging system, which are all widely cited. His research has been reported widely by significant media, including Discovery, Scientific American, MIT Tech Review, Public Radio, NPR, and CBS. Wang also received an NSF Career award and the endowed PNC Technologies Career Development Professorship.

_Talk title: "Understanding Gender Stereotypes and Electoral Success from Visual Self-presentations of Politicians in Social Media"_

<br/>

## Program (tentative)

ATQAM will take place from 8:00AM to 11:AM on the 12th of October 2020.

Name of Session | Time
-- | -- 
**Front Matter** | 8:00 - 8:05 AM
**Keynote & Invited Talks** | 8:05 - 9:10 AM
Speeding it Up: Perception of High-Frame Rate Videos | 8:05 - 8:50 AM
Going Big or Going Precise: Considerations in building the next-gen VQA Database | 8:50 - 9:10 AM
**Session 1** | 9:10 - 9:30 AM
EVA: An Explainable Visual Aesthetics Dataset | 9:10 - 9:30 AM
_Coffee Break_ | 9:30 - 9:40 AM
**Keynote & Invited Talks** | 9:40 - 11:00 AM
Modeling Aesthetics and Emotions in Visual Content - From Vincent van Gogh to Robotics and Vision | 9:40 - 10:20 AM
Rating  Distribution & Personality Prediction for Image Aesthetics Assessment | 10:20 - 10:40 AM
From Technical to Aesthetics Quality Assessment and Beyond: Challenges and Potential | 10:40 - 11:00 AM
_Lunch Break_ |    

<br/>

## Organizers

<table id="profile">
    <tr>
     <td><a href="mailto:whcheng@nctu.edu.tw"><img src="assets/images/wen-huang.png" class="profile"/></a></td>
     <td><a href="mailto:bastian.goldluecke@uni-konstanz.de"><img src="assets/images/bastian-goldlueke.png" class="profile"/></a></td>
     <td><a href="mailto:vlad.hosu@uni-konstanz.de"><img src="assets/images/vlad-hosu.png" class="profile"/></a></td>
     <td><a href="mailto:WSLin@ntu.edu.sg"><img src="assets/images/weisi-lin.png" class="profile"/></a></td>
     <td><a href="mailto:dietmar.saupe@uni-konstanz.de"><img src="assets/images/dietmar-saupe.png" class="profile"/></a></td>
     <td><a href="mailto:johnsee@mmu.edu.my"><img src="assets/images/john-see.png" class="profile"/></a></td>
     <td><a href="mailto:lkwong@mmu.edu.my"><img src="assets/images/lai-kuan-wong.png" class="profile"/></a></td>
    </tr>
    <tr align="top">
     <td> <a href="http://aimmlab.nctu.edu.tw/whcheng/index.html">
      Wen-Huang<br/> Cheng</a><br/> NCTU,<br/> Taiwan </td>
     <td> <a href="https://www.cvia.uni-konstanz.de/personen/prof-dr-bastian-goldluecke/">
      Bastian<br/> Goldlücke</a><br/> Uni-KN, Germany </td>
     <td> <a href="https://www.mmsp.uni-konstanz.de/people/overview/research-staff/vlad-hosu/">
      Vlad<br/> Hosu</a><br/> Uni-KN, Germany </td>
     <td> <a href="https://www.ntu.edu.sg/home/wslin/">
      Weisi<br/> Lin</a><br/> NTU, Singapore </td>
     <td> <a href="https://www.mmsp.uni-konstanz.de/people/overview/prof-dr-dietmar-saupe/">
      Dietmar<br/> Saupe</a><br/> Uni-KN, Germany </td>
     <td> <a href="https://mmuexpert.mmu.edu.my/johnsee">
      John<br/> See</a><br/> MMU, Malaysia </td>
     <td> <a href="https://mmuexpert.mmu.edu.my/lkwong">
      Lai-Kuan<br/> Wong</a><br/> MMU, Malaysia </td>
    </tr>
    <!--<tr align="top">
     <td/> <td/> 
     <td><a href="mailto:vlad.hosu@uni-konstanz.de"><img src="assets/images/email-icon.png" style="width:25px"/></a></td> 
     <td/> <td/> 
     <td><a href="mailto:johnsee@mmu.edu.my"><img src="assets/images/email-icon.png" style="width:25px"/></a></td>
     <td><a href="mailto:lkwong@mmu.edu.my"><img src="assets/images/email-icon.png" style="width:25px"/></a></td>
    </tr>-->
</table>

**Primary contacts**: [Vlad Hosu](mailto:vlad.hosu@uni-konstanz.de), [John See](mailto:johnsee@mmu.edu.my) and [Lai Kuan Wong](mailto:lkwong@mmu.edu.my).

## Technical Program Committee

* Seyed Ali	Amirshahi	- NTNU, Norway
* Raouf	Hamzaoui	- De Montfort University, UK
* Matthias Hirth -	TU Ilmenau, Germany
* Shujun	Li	- University of Kent, UK
* Hanhe	Lin	- University of Konstanz, Germany
* Yuen Peng	Loh	- Multimedia University, Malaysia

## Sponsor
<a href="https://www.sfbtrr161.de/"><img src="assets/images/sfbtrr161-logo.png" alt="SFB TRR 161" style="display: block; margin-left: auto; margin-right: auto; width: 50%"/></a>
